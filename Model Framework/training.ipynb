{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#import library\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pickle \n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import shutil\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score \n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing the Holistic Model from Mediapipe and\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "# Initializing the Model\n",
    "holistic_model = mp_holistic.Holistic(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    " \n",
    "# Initializing the drawing utils for drawing the facial landmarks on image\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Test_cam():\n",
    "    # (0) in VideoCapture is used to connect to your computer's default camera\n",
    "    capture = cv2.VideoCapture(0)\n",
    "\n",
    "    # Initializing current time and precious time for calculating the FPS\n",
    "    previousTime = 0\n",
    "    currentTime = 0\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    while capture.isOpened():\n",
    "        # capture frame by frame\n",
    "        ret, frame = capture.read()\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        # resizing the frame for better view\n",
    "        frame = cv2.resize(frame, (860,645))\n",
    "\n",
    "        # Converting the from BGR to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Making predictions using holistic model\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        results = holistic_model.process(image)\n",
    "        image.flags.writeable = True\n",
    "\n",
    "        # Converting back the RGB image to BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image, \n",
    "            results.pose_landmarks, \n",
    "            mp_holistic.POSE_CONNECTIONS,            \n",
    "        )\n",
    "        # Calculating the FPS\n",
    "        currentTime = time.time()\n",
    "        fps = 1 / (currentTime-previousTime)\n",
    "        previousTime = currentTime\n",
    "\n",
    "        # represents the top left corner of rectangle\n",
    "        start_point = (200, 10)\n",
    "\n",
    "        # represents the bottom right corner of rectangle\n",
    "        end_point = (680, 630)\n",
    "\n",
    "        # Blue color in BGR\n",
    "        color = (0,255,255)\n",
    "\n",
    "        # Line thickness of 2 px\n",
    "        thickness = 4\n",
    "\n",
    "        # Using cv2.rectangle() method\n",
    "        # Draw a rectangle with blue line borders of thickness of 2 px\n",
    "        cv2.rectangle(image, start_point, end_point, color, thickness)\n",
    "\n",
    "\n",
    "        # Displaying FPS on the image\n",
    "        cv2.putText(image, str(int(fps))+\" FPS\", (10, 70), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "\n",
    "        # Display Timer\n",
    "        cv2.putText(image, 'TIME'\n",
    "                    , (300,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, f\"{int(elapsed_time)} Sec\"\n",
    "                    , (350,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Display the resulting image\n",
    "        cv2.imshow(\"Test Camera\", image)\n",
    "\n",
    "        # Enter key 'q' to break the loop\n",
    "        if cv2.waitKey(5) & 0xFF == ord('q') or cv2.waitKey(5) & int(elapsed_time) == 5:\n",
    "            break\n",
    "\n",
    "    # When all the process is done\n",
    "    # Release the capture and destroy all windows\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "#Test_cam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waistFeetAndLegRaises = [\"wflr0\",\"wflr1\",\"wflr2\",\"wflr3\"]\n",
    "stompingAndBent = [\"sab0\",\"sab1\",\"sab2\"]\n",
    "fistAndStride = [\"fas0\",\"fas1\",\"fas2\",\"fas3\"]\n",
    "stretchOutAndStepBack  = [\"ss0\",\"ss1\",\"ss2\",\"ss3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"stretchOutAndStepBack\"\n",
    "\n",
    "#create folder of the model \n",
    "modelFolerPath = f\"Dataset/{model_name}\"\n",
    "if not os.path.exists(modelFolerPath):\n",
    "    os.makedirs(modelFolerPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = stretchOutAndStepBack[0]\n",
    "\n",
    "# Absolute path of a file\n",
    "go_src_path = r\"Dataset/predataset.csv\"\n",
    "go_dst_path = f\"Dataset/{model_name}/predataset.csv\"\n",
    "data_path = f\"Dataset/{model_name}/{class_name}.csv\"\n",
    "\n",
    "# Copying and rename the file\n",
    "if not os.path.isfile(data_path):\n",
    "    shutil.copy(go_src_path, go_dst_path)\n",
    "    os.rename(go_dst_path, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Camera\n",
    "Test_cam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# (0) in VideoCapture is used to connect to your computer's default camera\n",
    "capture = cv2.VideoCapture(0)\n",
    " \n",
    "while capture.isOpened():\n",
    "    # capture frame by frame\n",
    "    ret, frame = capture.read()\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    " \n",
    "    # resizing the frame for better view\n",
    "    frame = cv2.resize(frame, (860,645))\n",
    " \n",
    "    # Converting the from BGR to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    " \n",
    "    # Making predictions using holistic model\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    results = holistic_model.process(image)\n",
    "    image.flags.writeable = True\n",
    " \n",
    "    # Converting back the RGB image to BGR\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    mp_drawing.draw_landmarks(\n",
    "        image, \n",
    "        results.pose_landmarks, \n",
    "        mp_holistic.POSE_CONNECTIONS,            \n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        pose = results.pose_landmarks.landmark\n",
    "        pose_row = list(np.array([[landmark.x,landmark.y,landmark.z,landmark.visibility] for landmark in pose]).flatten())\n",
    "\n",
    "        pose_row.insert(0, class_name)\n",
    "            \n",
    "        with open(data_path, mode='a', newline='') as f:\n",
    "            csv_writer = csv.writer(f, delimiter=',')\n",
    "            csv_writer.writerow(pose_row)\n",
    "        \n",
    "        # represents the top left corner of rectangle\n",
    "        start_point = (200, 10)\n",
    "        \n",
    "        # represents the bottom right corner of rectangle\n",
    "        end_point = (680, 630)\n",
    "        \n",
    "        # Blue color in BGR\n",
    "        color = (0,255,255)\n",
    "        \n",
    "        # Line thickness of 2 px\n",
    "        thickness = 4\n",
    "        \n",
    "        # Using cv2.rectangle() method\n",
    "        # Draw a rectangle with blue line borders of thickness of 2 px\n",
    "        cv2.rectangle(image, start_point, end_point, color, thickness)\n",
    "\n",
    "        # Get status box\n",
    "        cv2.rectangle(image, (0,0), (500, 60), (255, 255, 255), -1)\n",
    "        \n",
    "        # Display Timer\n",
    "        cv2.putText(image, 'TIME'\n",
    "                    , (300,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, f\"{int(elapsed_time)} Sec\"\n",
    "                    , (350,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            \n",
    "    except:\n",
    "        cv2.putText(image, str('Out of Frame')\n",
    "                    , (210,150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow(\"Test Data\", image)\n",
    " \n",
    "    # Enter key 'q' to break the loop\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q') or cv2.waitKey(5) & int(elapsed_time) == 20:\n",
    "        break\n",
    " \n",
    "# When all the process is done\n",
    "# Release the capture and destroy all windows\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"stretchOutAndStepBack\"\n",
    "modelFolerPath = f\"Dataset/{model_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over files in data directory\n",
    "list_class = []\n",
    "list_data = []\n",
    "directory = modelFolerPath+\"/\"\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "        list_data.append(pd.read_csv(f))\n",
    "        x = filename.split(\".\")\n",
    "        list_class.append(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout.write(\"[  There is \" + str(len(list_class)) + \" class for this model  ]\\n\")\n",
    "print(\"==============================================================================\")\n",
    "for i in list_class:\n",
    "    print(i)\n",
    "\n",
    "print(\"==============================================================================\")\n",
    "df_model = pd.concat(list_data,ignore_index=True)\n",
    "print(\"df_model is now complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_model.drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_model .drop('class', axis=1) \n",
    "y = df_model ['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier(), verbose = 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(x_train, y_train)\n",
    "    fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for algo, model in fit_models.items():\n",
    "    yhat = model.predict(x_test)\n",
    "    print(algo, accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dst= f\"Model/{mode_name}.pkl\"\n",
    "pickle.dump(fit_models['rf'],open(save_dst, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "cd727cbb1243437093d01532431a410f1c77914a7505105a1e38d5b7c2d77c51"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
